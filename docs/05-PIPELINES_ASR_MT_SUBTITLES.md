# AI/字幕处理流水线（ASR / MT / 写回）

> 面向：算法/后端工程师

---

## 1. 流水线阶段

1. **模型准备**：确保 Ollama 模型（缺失则 `/api/pull`）。
2. **输入识别**：
   - 有文本字幕（SRT/ASS/VTT）→ 进入翻译。
   - 无字幕 → **ASR**。
3. **ASR**（可选）：FFmpeg 抽音 → faster‑whisper → 输出 SRT/VTT。
4. **翻译（MT）**：按条（或语义合并）调用 LLM 翻译，仅替换文本。
5. **后处理**：标点/空白/行长/换行/标签回填。
6. **写回**：Jellyfin `UploadSubtitle`（首选）或侧车文件。
7. **登记**：`subtitles` 表写入，刷新 `media_subtitle_langs`。

---

## 2. ASR 细节（faster‑whisper）

- **输入**：16kHz mono WAV（FFmpeg 提取）。
- **参数**：`compute_type="auto"`；长音频按窗口分段并重叠。
- **输出**：SRT/VTT（带起止时间），作为 MT 输入。
- **性能**：支持 8bit 量化，内存友好；GPU/CPU 自适应。

---

## 3. MT 细节（Ollama）

- **接口**：`/api/generate`（或 `/api/chat`）；`/api/pull` 获取模型。
- **提示词策略**：
  - 系统提示：专业字幕译者；不得添加/省略信息；
  - 用户模板：传入源语言、目标语言、纯文本；
  - **只返回译文**，不包含时间戳/编号。
- **批处理**：可按 N 行合并，控制 token 与上下文一致性。

---

## 4. 字幕格式与标签

- **pysubs2** 读写 `.srt/.ass/.vtt`；ASS 标签如 `{\i1}`、位置/描边需原样保留。
- 处理策略：  
  1) 解析 → **剥离标签** 得到纯文本；  
  2) 译文生成 → **回填标签**；  
  3) 行宽/换行按目标语言策略重排。

---

## 5. 质量保障

- 规则检查：空字幕、连续重复、过长行等。
- 术语表/禁译词：翻译前替换（占位符）与翻译后还原。
- 采样抽检：每 N 段一条人工复核；保留审校记录。
